{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Pré-processamento dos dados textuais\n",
    "\n",
    "## Transformando os dados em um dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip -q install pandas\n",
    "!pip -q install unidecode\n",
    "!pip -q install nltk\n",
    "!pip -q install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.cluster import hierarchy\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "#import limpeza dos dados\n",
    "import nltk\n",
    "import unidecode\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_base = pd.read_json('goodreads_books.json')\n",
    "n_samples = 1000\n",
    "\n",
    "#df_mini = df_base.sample(n=n_samples, random_state=1)\n",
    "#df_mini.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "        book_id                                        description     genre  \\\n29584  27237230  Laureate na nOg Eoin Colfer, author of the bes...  children   \n27290  30267927  DreamWorks Animation's TROLLS is an irreverent...  children   \n8046   16250909  Yoko and her mama are going on a trip to Japan...  children   \n28484  17428684  Minnie and friends get ready to pamper their p...  children   \n31456  30135659  One summer's day. ten-year-old India Opal Bulo...  children   \n\n      language_code  \n29584           eng  \n27290           eng  \n8046            eng  \n28484           eng  \n31456           eng  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>book_id</th>\n      <th>description</th>\n      <th>genre</th>\n      <th>language_code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>29584</th>\n      <td>27237230</td>\n      <td>Laureate na nOg Eoin Colfer, author of the bes...</td>\n      <td>children</td>\n      <td>eng</td>\n    </tr>\n    <tr>\n      <th>27290</th>\n      <td>30267927</td>\n      <td>DreamWorks Animation's TROLLS is an irreverent...</td>\n      <td>children</td>\n      <td>eng</td>\n    </tr>\n    <tr>\n      <th>8046</th>\n      <td>16250909</td>\n      <td>Yoko and her mama are going on a trip to Japan...</td>\n      <td>children</td>\n      <td>eng</td>\n    </tr>\n    <tr>\n      <th>28484</th>\n      <td>17428684</td>\n      <td>Minnie and friends get ready to pamper their p...</td>\n      <td>children</td>\n      <td>eng</td>\n    </tr>\n    <tr>\n      <th>31456</th>\n      <td>30135659</td>\n      <td>One summer's day. ten-year-old India Opal Bulo...</td>\n      <td>children</td>\n      <td>eng</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mini = pd.DataFrame(data=None, columns=df_base.columns)\n",
    "PER_GENRE = 200\n",
    "for g in df_base['genre'].unique():\n",
    "    aux_df = df_base[df_base.genre == g].sample(PER_GENRE, random_state=7)\n",
    "    df_mini = pd.concat([df_mini, aux_df], axis=0)\n",
    "df_mini.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "children                  200\ncomics_graphic            200\nfantasy_paranormal        200\nhistory_biography         200\nmystery_thriller_crime    200\npoetry                    200\nromance                   200\nyoung_adult               200\nName: genre, dtype: int64"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mini['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Limpeza dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/igor/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/igor/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/igor/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/igor/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def remove_specials(tokens):\n",
    "    return [unidecode.unidecode(word) for word in tokens]\n",
    "\n",
    "def remove_punctuation(tokens):\n",
    "    table = str.maketrans(\"\",\"\",string.punctuation)\n",
    "    return [w.translate(table) for w in tokens]\n",
    "\n",
    "def array_lower(tokens):\n",
    "    return [w.lower() for w in tokens]\n",
    "\n",
    "def remove_no_words(tokens):\n",
    "    return [word for word in tokens if word.isalpha()]\n",
    "\n",
    "def remove_stop_words(tokens):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return [w for w in tokens if not w in stop_words]\n",
    "\n",
    "def text_clean(df_text_column, log=False):\n",
    "    if log: print(\"Starting\")\n",
    "\n",
    "    # Dividindo texto em tokens\n",
    "    df_text_column = df_text_column.apply(word_tokenize)\n",
    "\n",
    "    if log: print(\"Tokens split done\")  # Some log\n",
    "\n",
    "    # Convertendo texto para minusculo\n",
    "    df_text_column = df_text_column.apply(array_lower)\n",
    "\n",
    "    if log: print(\"Upper letters converted to normal\")\n",
    "\n",
    "    # Removendo pontuação\n",
    "    df_text_column = df_text_column.apply(remove_punctuation)\n",
    "\n",
    "    if log: print(\"Removed punctiation\")\n",
    "\n",
    "    # Removendo caracteres especiais\n",
    "    df_text_column = df_text_column.apply(remove_specials)\n",
    "\n",
    "    if log: print(\"Specials chars removed\")\n",
    "\n",
    "    # Removendo tokens que não sao palavras\n",
    "    df_text_column = df_text_column.apply(remove_no_words)\n",
    "\n",
    "    if log: print(\"Removed non-words tokens\")\n",
    "\n",
    "    # Removendo tokens que são stop words\n",
    "    df_text_column = df_text_column.apply(remove_stop_words)\n",
    "\n",
    "    if log: print(\"Removed tokens that are stop-words\\nFinished\")\n",
    "\n",
    "    return df_text_column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Auxiliar log function\n",
    "def size_df(d):\n",
    "    print(\"Size=\", d.memory_usage(deep=True).sum()/10**9, \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        book_id                                        description     genre  \\\n29584  27237230  [laureate, na, nog, eoin, colfer, author, best...  children   \n27290  30267927  [dreamworks, animation, trolls, irreverent, co...  children   \n8046   16250909  [yoko, mama, going, trip, japan, yoko, helps, ...  children   \n28484  17428684  [minnie, friends, get, ready, pamper, pets, mi...  children   \n31456  30135659  [one, summer, day, tenyearold, india, opal, bu...  children   \n\n      language_code  \n29584           eng  \n27290           eng  \n8046            eng  \n28484           eng  \n31456           eng  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>book_id</th>\n      <th>description</th>\n      <th>genre</th>\n      <th>language_code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>29584</th>\n      <td>27237230</td>\n      <td>[laureate, na, nog, eoin, colfer, author, best...</td>\n      <td>children</td>\n      <td>eng</td>\n    </tr>\n    <tr>\n      <th>27290</th>\n      <td>30267927</td>\n      <td>[dreamworks, animation, trolls, irreverent, co...</td>\n      <td>children</td>\n      <td>eng</td>\n    </tr>\n    <tr>\n      <th>8046</th>\n      <td>16250909</td>\n      <td>[yoko, mama, going, trip, japan, yoko, helps, ...</td>\n      <td>children</td>\n      <td>eng</td>\n    </tr>\n    <tr>\n      <th>28484</th>\n      <td>17428684</td>\n      <td>[minnie, friends, get, ready, pamper, pets, mi...</td>\n      <td>children</td>\n      <td>eng</td>\n    </tr>\n    <tr>\n      <th>31456</th>\n      <td>30135659</td>\n      <td>[one, summer, day, tenyearold, india, opal, bu...</td>\n      <td>children</td>\n      <td>eng</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mini['description'] = text_clean(df_mini['description'])\n",
    "df_mini.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# df_base.loc[51285, 'description'] # Noisy data"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Lemmazation\n",
    "Instead of Stemming who reduce inflexions to your base word we could use instead the Lemmazation approuch which groups differented inflexions form of a word"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "execution_count": 26
  },
  {
   "cell_type": "raw",
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "lemmazation = lambda words: [wordnet_lemmatizer.lemmatize(tk) for tk in words]\n",
    "df_mini['description'] = df_mini['description'].apply(lemmazation)\n",
    "df_mini.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2 style=\"color:#ff3344\">Observation</h2>\n",
    "<span>The code above was converted to a raw cell in order to don't execute until we have a proof that <b>Lemmazation</b> is useful</span>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stemming"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "        book_id                                        description     genre  \\\n29584  27237230  [laureat, na, nog, eoin, colfer, author, bests...  children   \n27290  30267927  [dreamwork, anim, troll, irrever, comedi, extr...  children   \n8046   16250909  [yoko, mama, go, trip, japan, yoko, help, mama...  children   \n28484  17428684  [minni, friend, get, readi, pamper, pet, minni...  children   \n31456  30135659  [one, summer, day, tenyearold, india, opal, bu...  children   \n\n      language_code  \n29584           eng  \n27290           eng  \n8046            eng  \n28484           eng  \n31456           eng  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>book_id</th>\n      <th>description</th>\n      <th>genre</th>\n      <th>language_code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>29584</th>\n      <td>27237230</td>\n      <td>[laureat, na, nog, eoin, colfer, author, bests...</td>\n      <td>children</td>\n      <td>eng</td>\n    </tr>\n    <tr>\n      <th>27290</th>\n      <td>30267927</td>\n      <td>[dreamwork, anim, troll, irrever, comedi, extr...</td>\n      <td>children</td>\n      <td>eng</td>\n    </tr>\n    <tr>\n      <th>8046</th>\n      <td>16250909</td>\n      <td>[yoko, mama, go, trip, japan, yoko, help, mama...</td>\n      <td>children</td>\n      <td>eng</td>\n    </tr>\n    <tr>\n      <th>28484</th>\n      <td>17428684</td>\n      <td>[minni, friend, get, readi, pamper, pet, minni...</td>\n      <td>children</td>\n      <td>eng</td>\n    </tr>\n    <tr>\n      <th>31456</th>\n      <td>30135659</td>\n      <td>[one, summer, day, tenyearold, india, opal, bu...</td>\n      <td>children</td>\n      <td>eng</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter = PorterStemmer()\n",
    "stemmized = lambda d: [porter.stem(tk) for tk in d]\n",
    "df_mini['description'] = df_mini['description'].apply(stemmized)\n",
    "df_mini.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# TFIDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Using the hand made preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "   aan  aanslag  aantal  aardvark  aaron  abandon  abbadon  abbey  abbeybeast  \\\n0  0.0      0.0     0.0       0.0    0.0      0.0      0.0    0.0         0.0   \n1  0.0      0.0     0.0       0.0    0.0      0.0      0.0    0.0         0.0   \n2  0.0      0.0     0.0       0.0    0.0      0.0      0.0    0.0         0.0   \n3  0.0      0.0     0.0       0.0    0.0      0.0      0.0    0.0         0.0   \n4  0.0      0.0     0.0       0.0    0.0      0.0      0.0    0.0         0.0   \n\n   abbi  ...  zovigo   zu  zub  zur  zusak  zusj  zvezd  zwei  zwerg  zyzzyva  \n0   0.0  ...     0.0  0.0  0.0  0.0    0.0   0.0    0.0   0.0    0.0      0.0  \n1   0.0  ...     0.0  0.0  0.0  0.0    0.0   0.0    0.0   0.0    0.0      0.0  \n2   0.0  ...     0.0  0.0  0.0  0.0    0.0   0.0    0.0   0.0    0.0      0.0  \n3   0.0  ...     0.0  0.0  0.0  0.0    0.0   0.0    0.0   0.0    0.0      0.0  \n4   0.0  ...     0.0  0.0  0.0  0.0    0.0   0.0    0.0   0.0    0.0      0.0  \n\n[5 rows x 15305 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>aan</th>\n      <th>aanslag</th>\n      <th>aantal</th>\n      <th>aardvark</th>\n      <th>aaron</th>\n      <th>abandon</th>\n      <th>abbadon</th>\n      <th>abbey</th>\n      <th>abbeybeast</th>\n      <th>abbi</th>\n      <th>...</th>\n      <th>zovigo</th>\n      <th>zu</th>\n      <th>zub</th>\n      <th>zur</th>\n      <th>zusak</th>\n      <th>zusj</th>\n      <th>zvezd</th>\n      <th>zwei</th>\n      <th>zwerg</th>\n      <th>zyzzyva</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 15305 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_nothing = lambda x: x\n",
    "vect_manual = TfidfVectorizer(tokenizer=do_nothing, lowercase=False, preprocessor=do_nothing, ngram_range=(1, 1))\n",
    "freq = vect_manual.fit_transform(df_mini['description'].values.tolist())\n",
    "features = vect_manual.get_feature_names_out()\n",
    "df_freq = pd.DataFrame(data=freq.todense(), columns=features)\n",
    "df_freq.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Using only the class from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# vect = TfidfVectorizer(strip_accents='unicode', stop_words='english', ngram_range=(1, 1))\n",
    "# freq = vect.fit_transform(df_mini['description'].values.tolist())\n",
    "# df_freq = pd.DataFrame(data=freq.todense(), columns=vect.get_feature_names_out())\n",
    "# df_freq.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "N_COMPONENTS = 100\n",
    "pca = TruncatedSVD(n_components=N_COMPONENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pca.fit(df_freq)\n",
    "print(f\"Total variance explained: {np.sum(pca.explained_variance_ratio_):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_reduced = pca.transform(df_freq)\n",
    "df_freq_reduced = pd.DataFrame(data=freq_reduced, columns=list(range(N_COMPONENTS)))\n",
    "df_freq_reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "fig = plt.figure(figsize=(7, 5))\n",
    "plt.plot([i for i in range(1, pca.n_components + 1)], np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel(r'$k$ - Número de componentes principais')\n",
    "plt.ylabel(r'$f(k)$ - Fração cumulativa da variância explicada');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Aplicando o número máximo de componentes principais percebemos que talvez seja preciso um aumento no número de samples uma vez que o valor de componentes principais deve estar no intervalo entre\n",
    "$$\\left[0, \\ min(n_{samples} \\ , \\ n_{features}) \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analise da Quantidade de Grupos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silhoutte score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sc_evaluate_clusters(X, max_clusters, n_init, seed):\n",
    "    s = np.zeros(max_clusters+1)\n",
    "    s[0] = 0\n",
    "    s[1] = 0\n",
    "    for k in range(2, max_clusters+1):\n",
    "        kmeans = KMeans(init='k-means++', n_clusters = k, n_init = n_init, random_state = seed)\n",
    "        kmeans.fit_predict(X)\n",
    "        s[k] = metrics.silhouette_score(X, kmeans.labels_, metric = 'euclidean')\n",
    "    return s\n",
    "\n",
    "s = sc_evaluate_clusters(freq_reduced, 10, 10, 1)\n",
    "plt.plot(range(2, len(s)), s[2:], 'o-')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.title('$k$-means clustering performance on synthetic data')\n",
    "plt.ylabel('Silhouette Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dendogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidian_dists = metrics.euclidean_distances(df_freq_reduced.values)\n",
    "euclidian_dists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucli_dists = hierarchy.linkage(euclidian_dists)\n",
    "hierarchy.dendrogram(eucli_dists, color_threshold=1)\n",
    "# plt.figure(facecolor='white')\n",
    "plt.xticks([], [])\n",
    "plt.ylabel('Distância')\n",
    "plt.xlabel('Objetos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.manifold\n",
    "mds = sklearn.manifold.MDS(n_components=2, max_iter=1000, eps=1e-9, random_state=0,\n",
    "                   dissimilarity = \"precomputed\")\n",
    "fit = mds.fit(euclidian_dists)\n",
    "pos = fit.embedding_\n",
    "plt.scatter(pos[:, 0], pos[:, 1], s=8)\n",
    "plt.axis('square')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = df_mini['genre'].unique().size\n",
    "print(num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=2, random_state=42)\n",
    "y_pred = model.fit_predict(df_freq_reduced)\n",
    "# word_positions = {v: k for k, v in vectorizer.vocabulary_.items()}\n",
    "# cluster_ids = generate_wordclouds(X_svd, X_tfidf, 2, word_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "db8601ed9c6fae5528db3dc7d38939486afb7cc1a5a830919a58ef4bfd09cab6"
  },
  "kernelspec": {
   "display_name": "Python datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}